# Round 11 UEF Pattern Testing Usability Findings

Results overview from Round 11 of the user feedback sessions (conducted on April 27, 2016 @ Howard County Library, Miller Branch)

## Background

The Mobile UEF team conducted usability testing to evaluate specific UEF patterns in the context of a linear application on mobile and desktop devices. The existing iClaim and HR Portal applications were modified to evaluate particular patterns, including:

- Badge
- Container Show/Hide
- Critical Check Box
- Danger Notice
- Date and Time
- Dismissible Compact Notice
- File Upload
- Flag Notification
- Popover
- Progress
- Time
- Time Zone
- Tree Structure

Testing was conducted on the following types of devices: Smartphones (iOS and Android), Tablets(iOS and Android)

## The Prototype

The prototype was designed to incorporate two separate scenarios. The first scenario walked the participant through the modified iClaim application testing all patterns listed above except one. The Tree Structure pattern was shown in the second scenario within the modified HR Portal application due to its internal application origin.

## Viewport Sizes'

As with prior responsive prototypes used in Mobile UEF testing, this prototype was designed with a single breakpoint.

The devices with a viewport size of less than 768 pixels when used in portrait view included: the iPhone 5, iPhone 6, iPhone 6 Plus, Samsung Galaxy S5, Samsung Galaxy S6, Samsung Galaxy Note 4, and the Samsung Galaxy Note 5.

The devices with a viewport size of 768 and larger included the Samsung Galaxy Tab S2 and iPad.

The viewport sizes for each mobile device used in this round of testing are as follows:

| Mobile Device  | Viewport Size  | Operating System  |
|---|---|---|
| iPhone 5  | 320 x 568  | iOS  |
| Samsung Galaxy S5  | 360 x 640  | Android  |
| Samsung Galaxy S6  | 360 x 640  | Android  |
|Samsung Galaxy Note 4| 360 x 640| Android|
|Samsung Galaxy Note 5| 360 x 640| Android|
| iPhone 6  | 375 x 667  | iOS  |
|iPhone 6 Plus| 414 x 736 | iOS |
| iPad  | 768 x 1024  | iOS  |
| Samsung Galaxy Tab S2 | 800 x 1280  | Android  |

## What We Did

With members of the general public, Mobile UEF Team members:

- Conducted user testing with 15 participants on April 27, 2016 at the Howard County Public Library, Miller Branch location in Ellicott City, MD
  - Sixteen participants tested on one of the following types of devices:
    - Smartphone: 10 total participants
      - 1 using an iPhone 5
      - 3 using an iPhone 6
      - 1 using an iPhone 6 Plus
      - 5 using a Samsung Galaxy S6
    - Tablet: 5 total participants
      - 4 using an iPad
      - 1 using a Samsung Galaxy Note 10.1
- Collected participant information in a pre-test demographic survey, which indicated:
  - Participants ranged in age from 24 to 77, with a median age of 54;
  - All 15 participants own and use at least one type of mobile device;
  - Fourteen participants use their mobile device to complete one or more online activities;
  - Five participants have used Social Security’s online services;
  - Six participants would use a smartphone (2) or tablet (4) to access SSA.gov or a MySocialSecurity account.
- Analyzed the results, including:
  - Navigation methods and preferences;
  - Participant issues or comments regarding specific UEF patterns or screen details;
  - User satisfaction scores on the overall experience as indicated in a post-test questionnaire.

## Challenges & Constraints

As with prior Mobile UEF testing sessions, recruiting of volunteer participants was performed on-site during the testing session with outreach to a broad range of library patrons. The usability test scenario and tasks were designed to be completed within 15-20 minutes; prior mobile testing had shown this time range yielded the optimal balance of participants and data in any single day.

## Metrics

Metrics for this usability test were established by the Mobile UEF Workgroup as follows:

- Completion Rate – Percentage of participants who successfully completed the application without assistance
  - Target > 80% for each device type
- Ease of Use – Percentage of participants who indicated the application was “easy” or “very easy” to use, as measured by Questions #3, #5, and #8 of the post-test survey
  - Target > 80% for each device type
- User Satisfaction – Percentage of participants who indicated they were “satisfied” or “very satisfied,” as measured by questions #4 and #7 of the post-test survey
  - Target > 80% for each device type

## What We Learned

Metrics for task completion, ease of use and user satisfaction, as measured by the post-test questionnaire, were as follows:

| Metric  | Target (All Devices)  | Actual SmartPhone  | Actual Tablet  |
|---|---|---|---|
| Completion Rate  | >=80%  | 99%  | 98%  |
| Ease of Use  | >=80%  | 85%  | 80%  |
| User Satisfaction  | >=80%  | 94%  | 70%  |

### Post-Test Questionnaire

The following table lists the Post-Test Questionnaire responses by device type as well as overall.

Scale of 1-5 where 1 = lowest and 5=highest

| Questions  | Smartphone (n=10)  | Tablet (n=5)  |  Overall (n=15)  |
|---|---|---|---|
| How well did the website match your expectations?  | 3.89 | 3.60 | 3,79 |
| How well did the website support the task you were asked to perform?  | 3.78 | 3.20 | 3.57 |
| How difficult or easy was the website to use?  | 4.44 | 3.80 | 4.21 |
| Are you satisfied with the content?  | 4.33 | 4.00 | 4.21  |
| How difficult or easy was it to move through sections of the website? | 4.56 | 4.00 | 4.36 |
| How easy were the words on the website to understand?  | 4.33 | 4.20 | 4.29 |
| How satisfied are you with the speed at which you can complete tasks?  | 4.22 | 3.40 | 3.93 |
| How difficult or easy was it to find information you needed?  | 4.11 | 4.20 | 4.14 |
| How long would it take you to learn to use this website? | 4.25 | 5.00 | 4.50 |
| How confident did you feel using this application? | 4.00 | 4.25 | 4.08 |
| Average User Satisfaction Score by device type | 4.19 | 3.97 | 4.11 |

## Qualitative Assessment

This section discusses the usability issues, as well as observations and participant comments. The patterns tested within this evaluation group the findings.

### Flag Notification

1. Nine out of 15 participants (6 smartphone, 3 tablets) successfully closed the Flag Notification.
2. Six participants (4 smartphone, 2 tablets) did not close the notification because they didn’t think it was necessary.
3. When asked why they thought it was there, ten participants (5 smartphone, 5 tablets) stated that it was for informational purposes.
4. Three participants (1 smartphone, 2 tablets) stated that they did not notice the Flag at the top
5. One iPhone participant did not read the notification because they wanted to check the agreement.
6. One Galaxy S6 participant stated that they would prefer to see the notification be in a bar at the top of the page.
7. Location Preference

    7.1. Four participants (3 smartphone, 1 tablets) stated that it didn’t matter where the notification was located.

    7.2. Three participants (1 smartphone, 2 tablets) stated that they liked the notification where it currently is located.

    7.3. One Galaxy S6 participant would prefer the notice be a bar at the top of the page.

    7.4. One Galaxy Tab participant stated they would prefer it to be in the content so they do not miss the information.

### **Container (Show/Hide)**

1. There were no major issues with this pattern.
2. Eleven of the 15 participants (8 smartphone, 3 tablets) expanded the container with no issues.
3. One Galaxy Tab participant noticed that the container could expand but preferred to leave it closed.
4. One participant, who expanded the container, was unsure what the term ‘Less’ meant.

### **Critical Check Box**

1. There were no major issues with this pattern.
2. All 15 participants successfully selected the check box with no issues or prompting.

### **Progress**

1. Ten of the 15 participants (6 smartphone, 4 tablets) understood what the Progress pattern was indicating.
2. Nine participants (7 smartphone, 2 tablets) did not attempt to click on the Progress pattern because they did not think it looked clickable and felt it was purely informational.
3. Of the six participants who clicked on the pattern:
4. Three clicked on the bar and three clicked on the icon.
5. Four participants (2 smartphone, 2 tablets) needed prompting from the facilitator.
6. One iPhone participant expected to be able to click on the steps in the Popover.
7. One Galaxy S6 participant didn’t understand what their current step was.
8. One Galaxy S6 participant expected the icon to provide a list of what documentation they needed to provide for the current step.
9. One iPhone participant suggested making the Progress pattern a button so it’s more obvious.
10. Participant comments:

    10.1 “Why are they showing this?” (P11);

    10.2. “Why is it clickable?” (P14);

    10.3. “The ‘i’ [icon] might be clickable but it is very small and I didn’t notice it.” (P10)

### **Popover**

1. Nine participants (7 smartphone, 2 tablets) did not open the Popover because the Progress pattern did not look clickable.
2. Six participants (3 smartphone, 3 tablets) opened the Popover either on their own or with difficulty.
3. Once open, five of the six participants closed the Popover with no issues.
4. The sixth participant was able to close the Popover but had difficulty.

### **Time**

1. There were no major issues with this pattern.
2. Thirteen participants (9 smartphone, 4 tablets) successfully selected a time.
3. Of the thirteen participants, all of which stated that they liked the AM/PM field separate from the Time field because there was less scrolling through several options.
4. Twelve participants (7 smartphone, 5 tablets) stated that they expected the AM/PM field to start on AM because “gotta set one or the other” (P4).
5. Two participants (1 smartphone, 1 tablet) expected to see military time.

## **Time Zone**

1. There were no major issues with this pattern.
2. Fourteen participants (9 smartphone, 5 tablets) successfully selected a time zone.
3. Nine participants (5 smartphone, 4 tablets) stated that the amount of time zones in the list was what they expected.
4. Four participants (3 smartphone, 1 tablet) expected there to be more time zones listed.
5. Two expected international time zones for people who are abroad.
6. One expected more listed because she is used to world clocks.
7. One only expected Hawaii as an additional item to the list.
8. One Galaxy S6 participant didn’t expect to be asked for a time zone.

## **File Upload**

1. Adding a File

    1.1 Ten participants (8 smartphone, 2 tablets) successfully uploaded a document using the File Upload.

    1.2 Two iPhone participants attempted to type in the field before selecting the ‘Browse’ button.

    1.3 Two Galaxy S6 participants expected to see the file size after selecting the file. (Possible product of the testing scenario)

    1.4 One iPad participant didn’t understand what the term ‘Browse’ meant.

    1.5 One Galaxy S6 participant stated that adding a file from a phone is difficult; wouldn’t use a mobile device for something this important.

2. Removing a File

    2.1 Twelve participants (9 smartphone, 3 tablets) successfully removed the document from the field.

    2.2 One participant suggested a larger X icon.

    2.3 One participant suggested an edit button to change the file.

    2.4 One iPad participant commented, “I can’t tell if the files have been uploaded.” (P13)

## **Dismissible Compact Notice**

1. Nine out of 15 participants (5 smartphone, 4 tablets) did not close the Compact Notice.
2. Participants were frustrated and annoyed after seeing this notice.
3. Three participants stated they would not move on after seeing this notice because they did not know what to do next.
4. Participant Comments:

    4.1 “What do I do now?” (P3, P5)

    4.2 “I’m done, can’t do anything else” (P9)

## **Danger Notice**

1. All 15 participants noticed or commented on the Danger Notice.
2. Participants were frustrated and annoyed after seeing this notice.
3. Two smartphone participants did not want to move forward after seeing this pattern.
4. Two smartphone participants attempted to close out the Danger Notice by selecting on the X icon.
5. Two participants (1 smartphone, 1 tablet) wanted to save what they currently have and return another time.
6. Several participants could not tell the difference between the Danger Notice and the Warning Dismissible Compact Notice. (finding based on facilitator feedback in debrief)

## **Badge**

1. There were no major issues with this pattern.
2. Ten participants (5 smartphone, 5 tablets) noticed or commented on the Badge.
3. Three of the ten (2 smartphone, 1 tablet) had difficulty and needed prompting from the facilitator.
4. Two smartphone participants thought the badge looked like a button.
5. One iPad participant thought it had an interesting color scheme.

## **Date and Time**

1. There were no major issues with the functionality of this pattern
2. All 15 participants were able to successfully add a date and time
3. Five participants (3 smartphone, 2 tablets) thought it was easy to add a date and time
4. The icon used in the prototype was not understandable to participants
5. Participants were asked their preference on four different icons for this pattern. Results of this evaluation are below

**Participant Comments:**

> "That moved really fast"

### Icon Comments

## Date and Time

1. There were no major issues with the functionality of this pattern.
2. All 15 participants were able to successfully add a date and time.
3. Five participants (3 smartphone, 2 tablets) thought it was easy to add a date and time.
4. The icon used in the prototype was not understandable to participants.
5. Participants were asked their preference on four different icons for this pattern. Results of this evaluation are below.

**Participant Comments:**

General:

> “That moved really fast for me. Good menu.” (P1)
>
> “I like how it pops up with choices. Simple.” (P2)

Icon comments:

>“Weird looking, not a normal calendar.” (P4)
>
>“Looks like a camera, guessing it’s a calendar with a clock.” (P5)
>
>“Timer for a bomb or alarm clock. All you need is a clock or nothing at all.” (P6)
>
>“Either a battery about to explode or a calendar with a clock.” (P9)

## **Tree Structure**

Two of the 15 participants did not complete this task due to lack of time.

**Add an Employee:**

1. There were no issues with adding an employee.

2. Twelve participants (9 smartphone, 3 tablets) successfully added an employee to the Tree Structure.

3. One Galaxy S6 participant expected the newly added person to be highlighted.

**Navigate to and Delete an Employee:**

1. Ten of 13 participants (7 smartphone, 3 tablets) had difficulty or was unable to remove an employee from the Tree Structure.

2. Participants had no issues interacting with the Tree Structure when they were on a level they could see.

3. Most participants did not expect to have to expand “Philip Anderson” first in order to select “Joe Bensen”.

4. Four smartphone participants attempted to select Joe’s name (static text) from the content area to view his information.

5. Three participants (2 smartphone, 1 tablet) tried to remove Joe by selecting Edit or Delete while on Philip’s information.

6. One iPhone participant expected the chevron icon and the text to do the same action.

**Edit an Employee:**

1. All thirteen participants, who completed this task, successfully edited an employee in the Tree Structure.

**Participant comments:**

> “The arrow doesn’t imply that you have people.” (P2)

*The example used in the testing prototype pattern was based on an HR organizational structure.*

**Date and Time Icon Preference:**

At the end of the evaluation, the participants were shown four variations of the Date and Time pattern with different icons in each (pictured below). The facilitator then asked the participant their preference and why.

(A) (B) (C) (D)

Results show a strong preference for both ‘A’ and ‘D’. Six participants preferred ‘D’ and five preferred ‘A’.

The reasons participants preferred ‘D’ was because: 1) the icon tells them they are making an appointment and 2) it clearly shows both a calendar and clock. While participants who preferred ‘A’ said it was because it is simple and looks like a calendar.
One participant said that an icon was not necessary but if there must be an icon they would prefer a clock.
No participants preferred icon ‘B’; and three preferred icon ‘C’ because it was bigger and looked like a clock.

## Recommendations and Next Steps

Based on this round of testing, the following patterns were found to be problematic for enough participants to necessitate retesting or design refinements:
• Progress
• Popover
• Dismissible Compact Notice
• Date and Time
• Tree Structure

Pattern recommendations based on the findings are below.

| Pattern  | Recommendation  |  Rationale  |
|---|---|---|
|Flag Notification|Continue with the current design.|There were no major issues with this pattern.|
|Container Show/Hide|Continue with the current design.|There were no major issues with this pattern.|
|Critical Check Box|Continue with the current design.|There were no major issues with this pattern.|
|Progress|Re-evaluate the affordance for clicking on the pattern in order to open the Popover.|Most participants did not click on the pattern because they did not think it looked clickable.|
|Popover|Consider testing again within a new context to verify the issues are with the Progress pattern and not with the Popover.|Participants were not able to open the Popover because the Progress pattern did not look clickable.|
|Time|Continue with the current design.|There were no major issues with this pattern.|
|Time Zone|Continue with the current design.|There were no major issues with this pattern.|
|File Upload|Continue with the current design.|There were no major issues with this pattern.|
|Dismissible Compact Notice|Consider re-testing with a different notice style to verify the issues were not scenario related.|Since the Danger Notice and Warning Compact Notice was shown in the same context, participants did not see many differences between them.|
|Danger Notice|Continue with the current design.|There were no major issues with this pattern.|
|Badge|Continue with the current design.|There were no major issues with this pattern.|
|Date and Time|Re-evaluate the icon used to represent the input selection.|Most participants did not understand the icon used.|
|Tree Structure|Re-evaluate the icon used to expand and collapse the tree nodes.|Participants did not expect there to be more items under the chevron icon and consequently did not attempt to click it.|
