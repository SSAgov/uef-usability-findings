# Round 18 UEF Pattern Testing Usability Findings

Results overview from Round 18 of the user feedback sessions

## Background

The UEF team conducted usability testing to evaluate specific UEF patterns in the context of a non-linear Pro Template application prototype on desktop devices.

The following patterns were evaluated in Round 18 Testing:

- PRO Template Responsive Navigation
- PRO Template Drop Down (Mega Menu) Tab
- PRO Template Collapsible Panels
- Date and Time
- Mega-Select (Radio)
- Advanced Table Filtering
- Table (Column Selector)
- Summary(Show/Hide)

## Methodology

The UXG UEF team conducted usability testing with six participants on October 15-16, 2019. The evaluations took place in the UXG labs at SSA. All evaluations were conducted on desktop computers.

Rapid Iterative Testing Evaluation (RITE) was the method of choice during round 18. The team conducted three rounds of evaluations with two participants at a time (six total participants). After each round, the facilitators and the UXG UEF team met for a half hour debrief. During each debrief the team discussed the issues found and potential changes to the patterns that would be shown to the next set of participants.

During each evaluation, participants walked through a series of scenarios that allowed them to look at each of the patterns being tested. The prototype design was a fictitious internal vendor management system. The prototype was built with HTML and Axure.

## Participant Information

Six participants were involved in the evaluations. Their demographic information was as follows:

- Participants were between the ages of 22 and 70 with an average age of 50
- One out of six participants had a degree of higher education (4-year or graduate)
  - One participant had a 4-year degree
  - Two participants had a 2-year degree
  - 3 participants had some college
- Four out of six participants access the internet on a Desktop, Tablet and Smartphone
  - Six out of six participants access the internet on a Desktop
- Three out of six participants have a mySocialSecurity account online
- Five out of six participants use a mobile device for emails, browsing, news, social media and banking
- Four out of six participants would use a desktop or laptop to access SSA.gov
  - Two participants would use a tablet
  - One participant would not access SSA.gov

## Lessons Learned

The UXG team discussed lessons learned from this round of testing. Those included the following:

- The team liked the testing methodology used
- The team had no issues making updates to the Axure and HTML prototype
- Remember to clear cache after updates to the prototype
- Allow for more time to debrief the facilitators on any updates that were made to the prototype

## Metrics

Metrics for this usability test were established by the UEF Workgroup as follows. Each has a target of 80%.

- Completion Rate – Percentage of participants who successfully completed the application without assistance
- Ease of Use – Percentage of participants who indicated the application was “easy” or “very easy” to use, as measured by Questions #3, #5, and #8 of the post-test survey
- User Satisfaction – Percentage of participants who indicated they were “satisfied” or “very satisfied,” as measured by questions #4 and #7 of the post-test survey

## What We Learned

Metrics for task completion, ease of use and user satisfaction, as measured by the post-test questionnaire, were as follows:

| Metric  | Target  | Actual  |
|---|---|---|
|Completion Rate|>=80%|100%|
|Ease of Use|>=80%|84%|
|User Satisfaction|>=80%|81%|

The following table lists the Post-Test Questionnaire responses.

*Questions 9 and 10 were omitted because they were left out of the guide for most participants.
Participant 6 did not complete any of the questions.

### **Scale of 1-5, with 1 = lowest and 5=highest Overall**

| Post-Test Questionnaire Questions  | n=5  |
|---|---|
|1. How well did the website match your expectations?|3.4|
|2. How well did the website support the task you were asked to perform?|3.8|
|3. How difficult or easy was the website to use?|3.8|
|4. Are you satisfied with the content?|3.4|
|5. How difficult or easy was it to move through sections of the website?|3.4|
|6. How easy were the words on the website to understand?|3.2|
|7. How satisfied are you with the speed at which you can complete tasks?|3.6|
|8. How difficult or easy was it to find information you needed?|4|
|9. **Average User Satisfaction Score**|3.6|

### Qualitative Assessment

This section discusses the usability issues, as well as observations and participant comments. The patterns tested within this evaluation group the findings.

#### **PRO Template Collapsible Panels**

1. Four out of six participants had no issues with this pattern.
2. One participant was looking for an X icon. Also mentioned that the tooltip was very helpful.
3. P2 failed and was looking for an X icon
4. P3 passed but suggested we make the tooltip language editable

#### **PRO Template Drop Down (Mega Menu) Tab**

1. Three out of six participants had no issues (3 participants had difficulty).
2. Context was an issue for participants who had difficulty locating the menu
3. P3 mentioned the split functionality was confusing.
4. P4 participant may not have been given enough time to discover the tab on her own
5. P5 mentioned that the colors blended too much. She wanted to see bigger headers.

#### **Advanced Table Filtering**

1. 3 out of 6 participants had no issues
2. P1 could not discover the table filter, confused by settings thought it was something he would find in settings. Didn't like funnel icon.
3. P2 could not find the the advanced filter. Exhausted all of his options before actually selecting settings.
4. P2 liked the funnel icon.

#### **Table Column Selector**

1. 6 out of 6 participants had no issues.
2. P1 nice feature, liked the icon
3. P5 was looking for instruction tool tip

#### **Date and Time**

1. 6/6 participants had no issues
2. P1 liked the pattern but didn’t expect date and time to be combined.
3. P2 said “this is good”
4. P5 liked the pattern but suggested moving the save button up to the right.

#### **Mega-Select Radio**

1. 6/6 participants had no issues
2. P1 didn't want to go to the next page for more information
3. P3 felt it was more natural to scroll down rather than scroll to the right.
4. P5 liked the search capability

#### **Summary (Show/Hide)**

1. There were no major issues with this pattern.
2. P1, P2, P3 and P5 would have liked to see the information expanded by default

#### **Mega Menu (Mobile)**

1. 5 out of 6 participants had no issues ( 1participant had difficulty)
2. P2 scrolled down first before selecting Menu
3. P6 had no issues but did mention that there were too many layers to get to the page.

## Recommendations and Next Steps

Based on this round of testing, the following patterns were found to be problematic for enough participants to necessitate retesting or design refinements:

- Mega-Select (Radio)
- Advanced Table Filtering
- Date and Time
- Table (Column Selector)

Pattern recommendations based on the findings are below.

| Pattern  | Recommendation  |  Rationale  |
|---|---|---|
|PRO Template Responsive Navigation|Keep design as tested.||
|PRO Template Drop Down (Mega Menu) Tab|Keep design as tested.||
|PRO Template Collapsible Panels|Keep design as tested.||
|Date and Time|More research needed as to whether or not we need this as a pattern.||
|Mega-Select (Radio)|Update prototype with vertical scrolling||
|Advanced Table Filtering|Update Prototype without settings.||
|Table (Column Selector)|Keep design as tested.|Will wait to develop until Advanced Table Filtering has been figured out.|
|Summary (Show/Hide)|Keep design as tested.||
