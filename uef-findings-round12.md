# Round 12 UEF Pattern Testing Usability Findings

Results overview from Round 12 of the user feedback sessions (conducted on June 7, 2017 @ Howard County Library, Miller Branch)

## Background

The UEF team conducted usability testing to evaluate specific UEF patterns in the context of a linear application on mobile and desktop devices.
The following patterns were evaluated in Round 12 Testing:

- Dropdown Button
- Loading Button
- Progress
- Popover
- Full Page Calendar
- Tree Structure

Testing was conducted on the following types of devices: Smartphones (iOS and Android), Tablets (iOS), and Laptop (Windows)

## The Prototype

The prototype was designed to incorporate two separate scenarios. The first scenario walked the participant through a MySSA application testing all patterns listed above except one. The Tree Structure pattern was shown in the second scenario time permitting.

## Viewport Sizes

As with prior responsive prototypes used in Mobile UEF testing, this prototype was designed with a single breakpoint.
The devices with a viewport size of less than 768 pixels when used in portrait view included: the iPhone 5, and the Samsung Galaxy S3.
The devices with a viewport size of 768 and larger included the iPad and Laptop.

The viewport sizes for each mobile device used in this round of testing are as follows:

| Mobile Device  | Viewport Size  | Operating System  |
|---|---|---|
| iPhone 5  | 320 x 568  | iOS  |
| Samsung Galaxy S3  | 360 x 640  | Android  |
| iPad  | 768 x 1024  | iOS  |
| Laptop | 768 x 1024   | Windows  |

## What We Did

With members of the general public, Mobile UEF Team members:

- Conducted user testing with 15 participants on June 8 , 2016 at the Howard County Public Library, Miller Branch location in Ellicott City, MD
  - Fifteen participants tested on one of the following types of devices:
    - Smartphone: 8 total participants
      - 4 using an iPhone 5
      - 4 using a Samsung Galaxy S3
    - Tablet: 4 total participants
      - 4 using an iPad
    - Laptop: 3 Total participants
      - 3 using an HP Laptop
- Collected participant information in a pre-test demographic survey, which indicated:
  - Participants ranged in age from 24 to 77, with a median age of 54;
  - All 15 participants own and use at least one type of mobile device;
  - Fourteen participants use their mobile device to complete one or more online activities;
  - Five participants have used Social Security’s online services;
  - Six participants would use a smartphone (2) or tablet (4) to access SSA.gov or a MySocialSecurity account.
- Analyzed the results, including:
  - Navigation methods and preferences;
  - Participant issues or comments regarding specific UEF patterns or screen details;
  - User satisfaction scores on the overall experience as indicated in a post-test questionnaire.

## Challenges & Constraints

As with prior Mobile UEF testing sessions, recruiting of volunteer participants was performed on-site during the testing session with outreach to a broad range of library patrons. The usability test scenario and tasks were designed to be completed within 10 minutes; prior mobile testing had shown this time range yielded the optimal balance of participants and data in any single day.

## Metrics

Metrics for this usability test were established by the Mobile UEF Workgroup as follows:

- Completion Rate – Percentage of participants who successfully completed the application without assistance
  - Target > 80% for each device type
- Ease of Use – Percentage of participants who indicated the application was “easy” or “very easy” to use, as measured by Questions #3, #5, and #8 of the post-test survey
  - Target > 80% for each device type
- User Satisfaction – Percentage of participants who indicated they were “satisfied” or “very satisfied,” as measured by questions #4 and #7 of the post-test survey
  - Target > 80% for each device type

## What We Learned

Metrics for task completion, ease of use and user satisfaction, as measured by the post-test questionnaire, were as follows:

| Metric  | Target (All Devices)  | Actual SmartPhone  | Actual Tablet  | LapTop |
|---|---|---|---|---|
| Completion Rate  | >=80%  | 99%  | 98%  |85%|
| Ease of Use  | >=80%  | 85%  | 80%  |95%|
| User Satisfaction  | >=80%  | 94%  | 70%  |95%|

### Post-Test Questionnaire

The following table lists the Post-Test Questionnaire responses by device type as well as overall.

Scale of 1-5 where 1 = lowest and 5=highest

| Questions  | Smartphone (n=8)  | Tablet (n=4)  | Laptop (n=3)  | Overall (n=15)|
|---|---|---|---|---|
| How well did the website match your expectations?  | 4.6 |4.2 | 3.8 | 4.2|
| How well did the website support the task you were asked to perform?  | 4.8 | 4.6 |4.5 | 4.6|
| How difficult or easy was the website to use?  | 4.44 | 4.2| 3.8 | 4.1|
| Are you satisfied with the content?  | 4.33 | 4.00 | 4.0  | 4.1|
| How difficult or easy was it to move through sections of the website? | 4.56 | 4.0 | 4.0 | 4.1|
| How easy were the words on the website to understand?  | 4.4 | 4.5 | 4.8 | 4.5 |
| How satisfied are you with the speed at which you can complete tasks?  | 4.22 | 4.2| 4.0 | 4.1|
| How difficult or easy was it to find information you needed?  | 4.11 | 4.6 | 4.4 | 4.3|
| How long would it take you to learn to use this website? | 4.25 | 5.00 | 4.4 | 4.50 |
| How confident did you feel using this application? | 4.00 | 4.25 | 4.3 | 4.2 |
| Average User Satisfaction Score by device type | 4.37 | 4.35 | 4.2 | 4.27 |

### Qualitative Assessment

This section discusses the usability issues, as well as observations and participant comments. The patterns tested within this evaluation group the findings.

### **Dropdown Button**

1. 14  participants successfully opened the Dropdown Button. 1 Participant (P3) wanted to see all options (not in a drop down).
2. No issues or difficulty of use/understanding with the Dropdown Button.

### **Loading Button**

1. All 15 participants understood what the loading button was doing.
2. All participants found the loading button to be useful.
3. P6 thought it was calculating
4. P4 “It’s loading/submitting”

### **Progress**

1. 13 of 15 participants were confused by this pattern.

**Participant comments:**

General:
> Confused
>
> P22: “this page is useless”
>
> P23: “Nothing is clickable”
>
> “Surprised to see a help icon this page” –user didn’t want help with the progress.

Notes:
>Maybe “Steps” would be a better solution for the prototype?

Progress Bar not clickable:
> P22 “How come we couldn’t see this step at the beginning?”
>
> P1: clicked on bar (Tried to click on bar)

Clicking the Icon VS Help Link
> P1: Wanted to click the icon, but was unable.
>
> All users eventually clicked “help” link

### **Popover**

1. More info, not that helpful. Arrow would expand the line for more information”
2. Clicking the  popover, those would be links [to their steps]”Of the six participants who clicked on the pattern:

**Participant comments:**

General:
> P7, P13 Wanted to see a FAQ here not steps
>
> P22 Didn’t click anything. Didn’t know how to close the popover.
>
> P1, 23, 22: Difficulty opening/closing the popover. (Mobile users-Small screens and an older user)

### **Full Page Calendar**

**Participant comments:**

Filter:
> P11: “Filter was easy to use, need more time slots.”
>
> P1: Liked that it gave filter options
>
> P7: Would prefer month first
>
> P16, 13: Would use week view first, not month
>
> P2: “Filter not super friendly. Too much going on.” Wanted to see dates with times. Likes Kaiser Permanente scheduling calendar.
>
> P12: Didn’t see filtering options.

“Simple, easy to use.”
> “Didn’t ask what language.”
>
> “Basic, didn’t do much”
>
> “Switching between month, day, week was confusing.” (P6)
>
> “Should see a drop down once selected a date/time” (P6)

Issues with scrolling:
> P11: only saw till 2pm
>
> P16: Times started at 12am, 1am

Small Screens – Did they turn sideways?:
> P1, 3, 7: Didn’t like it at first, turned to view in landscape
>
> P3: Turned to landscape with no issues

General:
> P4: “See all day. I like that.”
>
> P16: “Clean/Clear, straightforward”
>
> P13: “As good as google. Better than Excel.”
>
> P12: “Convenient, easy. Not clear what is available.” Didn’t know the current day was highlighted.
>
> P2, 5: Couldn’t do it.
>
> P12: “Similar to other software”
>
> P1: “Don’t know how to get to them. Should show was is available”
>
> P1, 2, 4: Difficulty selecting a time (no other information was provided)

Notes:
> Larger screens were better. Next prototype, we take it a step further and allow the user to select an appointment.
>
>Users were shown appointments already taken, some users preferred seeing ones that were open instead.
>
>Should look at how Labcorp and Kaiser do their scheduling

### **Tree Structure**

1. P3, P13 and P15 ignored the tree structure to complete the tasks (incorrectly)

**Participant comments:**
Clicked the name, not the arrow for drop down:

> P5, 12: Wanted to see everyone below the manager when they click the name.
>
> P3, 12, 13, 16: Clicked the name, not the arrow (So didn’t see the names below the manager)
>
> P5: “Arrows aren’t clickable”
>
> P12: Knew it was clickable, but didn’t know it would expand
>
> P7: Thought the name and arrow was the same interaction

General:
> P15: Concerned the tree structure would be screwed up if they make any changes to the manager.

Notes:
Initial screen should be blank on the right hand side. (or have a “dummy info”). People were confused – and tried to interact in this section first, before using the tree structure (after prompting)

### **Summary**

1. Overall, what do you think of the website?

**Participant comments:**
General:
> People generally liked everything. Easy, straightforward

Look and Design comments:
> P5: “Not clear why were are doing this on the phone”
>
> P4: “pretty”

Like or Dislike:

> P12: “Not too much detail is good”
>
> P15: Didn’t like the tree structure
>
> P6: Tree structure: Scared of changing the entire branch
>
> P1: “Font and screen was too small to complete tasks” (using iPhone 5)

Add/Remove/Change:
> P14: “Blue is good, very gentle soft”
>
> P15: “If I can’t do it, don’t show it” (tree structure)
>
> P5: “Why would we use this on the phone?”
>
> P12: “Not too complicated”
>
> P15: “Without a stylus, it’s hard to click”
>
> P6: “Pleasant and refreshing”
>
> P4: “Smooth”
>
> P1: “Too small, problems with fingers and gestures”
>
> P23: Liked condition of the tree structure.

## Recommendations and Next Steps

Based on this round of testing, the following patterns were found to be problematic for enough participants to necessitate retesting or design refinements:

- Progress
- Full Page Calendar
- Tree Structure

Pattern recommendations based on the findings are below.

| Pattern  | Recommendation  |  Rationale  |
|---|---|---|
|Drop Down |Continue with the current design. |There were no major issues with this pattern.|
|Loading Button| Continue with the current design. |There were no major issues with this pattern.|
|Progress| Re-evaluate including more information about the current step. |Most participants did not realize the purpose of this pattern.|
|Popover| Continue with current design.| There were no major issues with this pattern.|
|Full Page Calendar| Re-evaluate filter options. Re-evaluate allowing users to select an actual date instead of a pre-selected date. | Participants wanted to see dates with times availability.|
|Tree Structure |Consider testing again within a new context to verify the issues are with the Tree Structure pattern and not with the scenario given to the user. |Participants did not click on the icon of the tree structure; rather they click on the text.|
