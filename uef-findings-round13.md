# Round 13 UEF Pattern Testing Usability Findings

Results overview from Round 13 of the user feedback sessions

## Background

The UEF team conducted usability testing to evaluate specific UEF patterns in the context of a linear application on mobile and desktop devices.

The following patterns were evaluated in Round 13 Testing:

- Progress Bar
- Tree Structure
- Multi Select
- Yes/No
- Toggle Button

Testing was conducted on the following types of devices: Smartphones (iOS and Android), Tablets (iOS), and Laptop (Windows 7)

## The Prototype

The prototype was designed to incorporate two separate scenarios. The first scenario walked the participant through completing information for an already submitted MySSA application testing all patterns listed above except one. The Tree Structure pattern was shown in the second scenario (time permitting).

## Viewport Sizes

As with prior responsive prototypes used in Mobile UEF testing, this prototype was designed with a single breakpoint.
The devices with a viewport size of less than 768 pixels when used in portrait view included the iPhone 5, iPhone 6, and Samsung Galaxy S3.

The devices with a viewport size of 768 and larger included the iPad, Laptop, and Galaxy Tab S2.

The viewport sizes for each mobile device used in this round of testing are as follows:

| Mobile Device  | Viewport Size  | Operating System  |
|---|---|---|
| iPhone 5  | 320 x 568  | iOS  |
| Samsung Galaxy S3  | 360 x 640  | Android  |
| Samsung Galaxy Tab S2  | 800 x 1280  | Android  |
| iPad  | 768 x 1024  | iOS  |
| Laptop | 768 x 1024   | Windows  |

## What We Did

With members of the general public, Mobile UEF Team members:

- Conducted user testing with 17 participants on October 23, 2017 at the Howard County Public Library, Miller Branch location in Ellicott City, MD
  - 17 participants tested on one of the following types of devices:
    - Smartphone: 8 total participants
      - 5 using a Galaxy S3
      - 3 using an Iphone5
    - Tablet: 6 total participants
      - 6 marked as using an iPad (Facilitators did not indicate whether or not a Galaxy Tab S2 was used)
    - Laptop: 3 Total participants
      - 3 using an HP Laptop
- Collected participant information in a pre-test demographic survey, which indicated:
  - Participants ranged in age from 22 to 69, with a median age of 54;
  - 16 participants own and use at least one type of mobile device;
  - 16 participants use their mobile device to complete one or more online activities;
  - Five participants have used Social Security’s online services;
  - Six participants would use a smartphone (2) or tablet (4) to access SSA.gov or a MySocialSecurity account.
- Analyzed the results, including:
  - Navigation methods and preferences;
  - Participant issues or comments regarding specific UEF patterns or screen details;
  - User satisfaction scores on the overall experience as indicated in a post-test questionnaire.

## Challenges & Constraints

As with prior Mobile UEF testing sessions, recruiting of volunteer participants was performed on-site during the testing session with outreach to a broad range of library patrons. The usability test scenario and tasks were designed to be completed within 10 minutes; prior mobile testing had shown this time range yielded the optimal balance of participants and data in any single day.

## Metrics

Metrics for this usability test were established by the Mobile UEF Workgroup as follows:

- Completion Rate – Percentage of participants who successfully completed the application without assistance
  - Target > 80% for each device type
- Ease of Use – Percentage of participants who indicated the application was “easy” or “very easy” to use, as measured by Questions #3, #5, and #8 of the post-test survey
  - Target > 80% for each device type
- User Satisfaction – Percentage of participants who indicated they were “satisfied” or “very satisfied,” as measured by questions #4 and #7 of the post-test survey
  - Target > 80% for each device type

## What We Learned

Metrics for task completion, ease of use and user satisfaction, as measured by the post-test questionnaire, were as follows:

| Metric  | Target (All Devices)  | Actual SmartPhone  | Actual Tablet  | LapTop |
|---|---|---|---|---|
| Completion Rate  | >=80%  | 99%  | 98%  |85%|
| Ease of Use  | >=80%  | 85%  | 80%  |95%|
| User Satisfaction  | >=80%  | 94%  | 70%  |95%|

The following table lists the Post-Test Questionnaire responses by device type as well as overall.

### Post-Test Questionnaire

The following table lists the Post-Test Questionnaire responses by device type as well as overall.

Scale of 1-5 where 1 = lowest and 5=highest

| Questions  | Smartphone (n=8)  | Tablet (n=6)  | Laptop (n=3)  | Overall (n=17)|
|---|---|---|---|---|
|1. How well did the website match your expectations?|4.6|4.2|3.8|4.2|
|2. How well did the website support the task you were asked to perform?|4.8|4.6|4.5|4.6|
|3. How difficult or easy was the website to use?|4.44|4.2|3.8|4.1|
|4. Are you satisfied with the content?|4.33|4.00|4.0|4.1|
|5. How difficult or easy was it to move through sections of the website?|4.56|4.00 |4.0|4.1|
|6. How easy were the words on the website to understand?|4.4|4.5|4.8|4.5|
|7. How satisfied are you with the speed at which you can complete tasks?|4.22|4.2|4.0|4.1|
|8. How difficult or easy was it to find information you needed?|4.1|4.6|4.4|4.3|
|9. How long would it take you to learn to use this website?|4.25|5.00|4.4|4.50|
|10. How confident did you feel using this application?|4.00|4.25|4.3|4.2|
|11. Average User Satisfaction Score by device type|4.37|4.35|4.2|4.27|

### Qualitative Assessment

This section discusses the usability issues, as well as observations and participant comments. The patterns tested within this evaluation group the findings.

#### **Dropdown Button**

1. 13 participants successfully opened the Dropdown Button.
2. 2 Participants (iPhone 5 and Samsung Galaxy S3) Couldn’t see below the fold.
3. No issues or difficulty of use/understanding with the Dropdown Button.

#### **Progress**

1. 15 participants had no issues with the progress pattern.
  1.1 One user testing on an iPad said the visibility of the 2nd “processing” was an issue
  1.2 One Samsung Galaxy S3 user wanted to see more information for the progress pattern.

#### **Toggle**

1. 6 of 17 participants were confused by this pattern

    1.1. 4 users (2 using an iPad and 2 using the Galaxy S3) asked “Where is the yes?”

    1.2. 2 users Didn’t know what to do with the toggle button.

    1.3. 1 user (Galaxy S3) said “Unsure I answered the way I want”

    1.4. 1 user (Galaxy S3) “Didn’t expect the circle to move”

    1.5. 2 users (Desktop), and (Galaxy S3) Tried to slide the circle. (similar to iPhone unlock interaction)

    1.6. 1 User (Desktop) was confused with the visuals: White circle matches the progress bar circle visually. Did not mean the same thing, contradictory messages.

    1.7. 1 user (Samsung Galaxy S3) Reluctant to click the circle. Thought it was going to take them to another page where they could see all options.

#### **Multi-Select**

1. 2 users (iPad & Desktop) liked alphabetical order. “What I expected”
2. 1 user (iPad) Entered China into search field (understood they were able to search)
3. 1 user (Galaxy S3) was unable to click arrow to open multi-select. (same user as above)
4. 1 user (Desktop) Clicked arrow first not “Select”
5. 1 user (Galaxy S3) Didn’t think ANYTHING was clickable. Not the Arrow or name.

#### **Tree Structure**

1. 11 of the 17 participants did not know the chevron was clickable.

**Participant comments:**

General:
> One user (iPad) said chevron looked similar to bullets, didn’t know it was clickable.
>
> One user (iPad) “Frustrating”
>
> Two users (iPad, iPad) Didn’t click arrow
>
> One user (Desktop) Saw red hover on name, but no red hover on chevron – didn’t know it as clickable
>
> One user (iPad) Clicked name, not arrow – never saw the names below
>
> One user (iPad) “Maybe plus sign would be better”
>
> One user (iPhone5) “Arrow and name should have same functionality” – paraphrasing
>
> One user (iPad) “Bold, different colors” confused which interaction are interactions  look this one up again

#### **Summary**

**Participant comments:**

Overall, what do you think of the website?

General:
> users thought it was very easy. Some made comments that it was too technical.

Look and Design:
> 1 user (iphone5): “Neat and Clean”
>
> 1 user (iphone5): “Its Fine”

Like or Dislike:
> 1 user (iphone5): “Not too much detail is good”
>
> 1 user (iPhone 5): Didn’t like the tree structure
>
> 1 user (Galaxy s3): Tree structure: Scared of changing the entire branch
>
> 1 user (iPhone 5): “Font and screen was too small to complete tasks” (using iPhone 5)

Add/Remove/Change:
> 1 user (iPad): “It would be nice to see all the steps”
>
> 1 user (iPad): “Would not access app from phone”
>
> 1 user (Desktop): “Why would we use this on a desktop?”
>
> 1 user (iPhone 5): “Not too complicated”

## Recommendations and Next Steps

Based on this round of testing, the following patterns were found to be problematic for enough participants to necessitate retesting or design refinements:

- Progress
- Tree Structure
- Toggle

Pattern recommendations based on the findings are below.

| Pattern  | Recommendation  |  Rationale  |
|---|---|---|
|Multi Select|Continue with the current design.|There were no major issues with this pattern.|
|Yes/N|Continue with the current design.|There were no major issues with this pattern.|
|Progress|Re-evaluate including more information about the current step.| Participants understood that it was a progress bar but wanted to see more information.|
|Tree Structure|Consider testing again with new icon. |Participants did not click on the icon of the tree structure; rather they click on the text.|
|Toggle|Re-evaluate including A/B testing.|Participants did not understand whether this pattern was clickable.|
